{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignnment_nn_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnLt2lAUApqb3rFq9EGQ2n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sainikhit2k/Automatic-assigment-grading-using-LSTM-RNN-and-NN/blob/master/TwoLayerNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw5Pqk4lVCeL",
        "colab_type": "code",
        "outputId": "50ecb4d8-5509-493b-ae5d-66282b0000d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from google.colab import files\n",
        "# files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  kaggle.json  sample_data  training_set_rel3.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzEGSdkWVCro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ipKGwvQVN0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3ZZWn1UVPsD",
        "colab_type": "code",
        "outputId": "b1a00804-dec1-4803-b547-1b278a566ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!kaggle competitions download -c asap-aes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading valid_set.tsv.zip to /content\n",
            "  0% 0.00/1.60M [00:00<?, ?B/s]\n",
            "100% 1.60M/1.60M [00:00<00:00, 111MB/s]\n",
            "Downloading training_set_rel3.tsv.zip to /content\n",
            "100% 4.86M/4.86M [00:00<00:00, 5.17MB/s]\n",
            "\n",
            "Training_Materials.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Downloading Essay_Set_Descriptions.zip to /content\n",
            "  0% 0.00/214k [00:00<?, ?B/s]\n",
            "100% 214k/214k [00:00<00:00, 65.7MB/s]\n",
            "Downloading valid_set.xlsx.zip to /content\n",
            "  0% 0.00/2.01M [00:00<?, ?B/s]\n",
            "100% 2.01M/2.01M [00:00<00:00, 66.1MB/s]\n",
            "Downloading valid_sample_submission_5_column.csv to /content\n",
            "  0% 0.00/88.5k [00:00<?, ?B/s]\n",
            "100% 88.5k/88.5k [00:00<00:00, 85.3MB/s]\n",
            "Downloading training_set_rel3.xlsx.zip to /content\n",
            " 81% 5.00M/6.20M [00:00<00:00, 7.50MB/s]\n",
            "100% 6.20M/6.20M [00:00<00:00, 9.08MB/s]\n",
            "Downloading valid_sample_submission_2_column.csv to /content\n",
            "  0% 0.00/41.4k [00:00<?, ?B/s]\n",
            "100% 41.4k/41.4k [00:00<00:00, 37.5MB/s]\n",
            "Downloading training_set_rel3.xls.zip to /content\n",
            " 91% 5.00M/5.49M [00:00<00:00, 6.31MB/s]\n",
            "100% 5.49M/5.49M [00:00<00:00, 6.65MB/s]\n",
            "Downloading valid_sample_submission_1_column_no_header.csv to /content\n",
            "  0% 0.00/14.9k [00:00<?, ?B/s]\n",
            "100% 14.9k/14.9k [00:00<00:00, 13.4MB/s]\n",
            "Downloading valid_sample_submission_1_column.csv to /content\n",
            "  0% 0.00/14.9k [00:00<?, ?B/s]\n",
            "100% 14.9k/14.9k [00:00<00:00, 12.8MB/s]\n",
            "Downloading valid_set.xls.zip to /content\n",
            "  0% 0.00/1.79M [00:00<?, ?B/s]\n",
            "100% 1.79M/1.79M [00:00<00:00, 121MB/s]\n",
            "test_set.tsv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fisXnTNRVfHu",
        "colab_type": "code",
        "outputId": "cb868e3c-7290-4c6e-84cf-644087298475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip training_set_rel3.tsv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  training_set_rel3.tsv.zip\n",
            "replace training_set_rel3.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPHhu-MgVkZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"training_set_rel3.tsv\", sep = \"\\t\", encoding = \"ISO-8859-1\")\n",
        "\n",
        "df = df[['essay', 'domain1_score']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya07TJ25VvzB",
        "colab_type": "code",
        "outputId": "fcfc2cd1-04e2-4ae5-f3a0-2efd2fb8d04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUKvNz_mWALS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n",
        "def essay_to_wordlist(essay):\n",
        "  essay = re.sub(\"[^a-zA-Z]\", \" \", essay)\n",
        "  words = essay.strip().lower().split()\n",
        "  stop_words = set(stopwords.words(\"english\"))\n",
        "  words = [w for w in words if w not in stop_words]\n",
        "  return words\n",
        "\n",
        "\n",
        "def essay_to_sentences(essay):\n",
        "  tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "  raw_sentences = tokenizer.tokenize(essay.strip())\n",
        "  sentences = []\n",
        "  for raw_sentence in raw_sentences:\n",
        "    if(len(raw_sentence) > 0):\n",
        "      sentences.append(essay_to_wordlist(raw_sentence))\n",
        "  return sentences\n",
        "\n",
        "def makeFeatureVec(words, model, num_features):\n",
        "  featureVec = np.zeros((num_features,))\n",
        "  num_words = 0\n",
        "  index2word = set(model.wv.index2word)\n",
        "  for word in words:\n",
        "    if word in index2word:\n",
        "      featureVec = np.add(featureVec, model[word])\n",
        "      num_words += 1\n",
        "  return np.divide(featureVec, num_words)\n",
        "\n",
        "\n",
        "def getFeatureVecs(essays, model, num_features):\n",
        "  feature_matrix = np.zeros((len(essays), num_features), dtype = \"float32\")\n",
        "  essay_count = 0\n",
        "  for essay in essays:\n",
        "    feature_matrix[essay_count] = makeFeatureVec(essay, model, num_features)\n",
        "    essay_count += 1\n",
        "  return feature_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKnT-C8dWHl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Dropout, Conv1D, Flatten\n",
        "from keras.models import Sequential\n",
        "\n",
        "def get_nn_model(num_dims = 300):\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters = 1, kernel_size = 3, input_shape = (num_dims, 1), strides = 3, padding = \"valid\"))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(300, activation = \"relu\"))\n",
        "  model.add(Dropout(rate = 0.5))\n",
        "  model.add(Dense(150, activation = \"relu\"))\n",
        "  model.add(Dropout(rate = 0.5))\n",
        "  model.add(Dense(1, activation = \"relu\"))\n",
        "  model.compile(loss = 'mean_squared_error', optimizer = 'rmsprop', metrics = ['mae'])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SZDbV6G-mSp",
        "colab_type": "code",
        "outputId": "a9acbabb-864f-43e8-83fb-54068409b573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df['essay']\n",
        "Y = df['domain1_score']\n",
        "print(len(X))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OOLZMylYXSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "def train_model(X, y, num_dims = 300, batch_size = 64, epochs = 50):\n",
        "  cv = KFold(n_splits = 5, shuffle = True)\n",
        "\n",
        "  # model_name = \"nn_\" + \"dims:\" + str(num_dims) + \"batch:\" + str(batch_size) + \"epochs:\" + str(epochs)\n",
        "  # word2vec_name = model_name + \":word2vec_model\"\n",
        "  fold_count = 1\n",
        "\n",
        "  best_hist = None\n",
        "  best_score = 0.0\n",
        "  best_model = None\n",
        "  best_word_vec = None\n",
        "\n",
        "  scores = []\n",
        "\n",
        "  for train_ind, test_ind in cv.split(X):\n",
        "\n",
        "    print(\"------------------Fold {}------------------\".format(fold_count))\n",
        "    X_train, X_test, Y_train, Y_test = X[train_ind], X[test_ind], Y[train_ind], Y[test_ind]\n",
        "\n",
        "    sentences = []\n",
        "    for essay in X_train:\n",
        "      sentences += essay_to_sentences(essay)\n",
        "    \n",
        "    min_word_count = 40\n",
        "    num_workers = 4\n",
        "    context = 10\n",
        "    downsampling = 1e-3\n",
        "\n",
        "    model = Word2Vec(sentences, workers = num_workers, size = num_dims, sample = downsampling, window = context)\n",
        "    print(\"Word2Vec model trained\")\n",
        "    \n",
        "    train_essays = [essay_to_wordlist(essay) for essay in X_train]\n",
        "    test_essays = [essay_to_wordlist(essay) for essay in X_test]\n",
        "\n",
        "    train_essays = getFeatureVecs(train_essays, model, num_dims)\n",
        "\n",
        "    test_essays = getFeatureVecs(test_essays, model, num_dims)\n",
        "    \n",
        "    train_essays = np.expand_dims(train_essays, axis = -1)\n",
        "    test_essays = np.expand_dims(test_essays, axis = -1)\n",
        "\n",
        "    nn_model = get_nn_model(num_dims=num_dims)\n",
        "    # nn_model.summary()\n",
        "    history = nn_model.fit(train_essays, Y_train.values, batch_size = batch_size, epochs = epochs)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    y_pred = nn_model.predict(test_essays)\n",
        "    y_pred = np.round(y_pred)\n",
        "\n",
        "    score = cohen_kappa_score(Y_test.values, y_pred, weights = \"quadratic\")\n",
        "    print(\"Kappa score: {}\".format(score))\n",
        "    scores.append(score)\n",
        "\n",
        "    if score > best_score:\n",
        "      best_score = score\n",
        "      best_hist = history\n",
        "      best_model = nn_model\n",
        "      best_word_vec = model\n",
        "\n",
        "\n",
        "    fold_count += 1\n",
        "  \n",
        "\n",
        "  \n",
        "  print(\"Best Score: {}\".format(best_score))\n",
        "  print(\"Average Kappa Score: {}\".format(np.mean(scores)))\n",
        "  return best_model, best_hist, best_score\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOcBsEH6nphr",
        "colab_type": "code",
        "outputId": "d09e445b-0ff3-41fc-852b-4d011be8f5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        }
      },
      "source": [
        "model, history, score = train_model(X, Y, num_dims=300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------Fold 1------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-b0859bc670ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-72-22c37245100d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X, y, num_dims, batch_size, epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtest_essays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_essays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;31m# nn_model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_essays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-e580c0236ffe>\u001b[0m in \u001b[0;36mget_nn_model\u001b[0;34m(num_dims)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_40: expected ndim=3, found ndim=2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaMp2uZyDXFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import json\n",
        "\n",
        "def save_model(model, history_dict, name):\n",
        "  model.save(name + \".h5\")\n",
        "  with open(name + \".p\", 'wb') as fp:\n",
        "    pickle.dump(history_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "save_model(model, history, \"300_64_50_trained\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpQNo-cstdwW",
        "colab_type": "code",
        "outputId": "3c41ad74-de98-4fee-808e-282811f64c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "model, history, score = train_model(X, Y, num_dims=200)\n",
        "save_model(model, history, \"200_64_50_trained\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------Fold 1------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-33b450ce960f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"200_64_50_trained\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-22c37245100d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X, y, num_dims, batch_size, epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtest_essays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_essays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;31m# nn_model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_essays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-e580c0236ffe>\u001b[0m in \u001b[0;36mget_nn_model\u001b[0;34m(num_dims)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_42: expected ndim=3, found ndim=2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTO9at1hyS5R",
        "colab_type": "code",
        "outputId": "bc30016b-e070-4a8e-fad3-25f17a63fc1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model, history, score = train_model(X, Y, num_dims=100)\n",
        "save_model(model, history, \"100_64_50_trained\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------Fold 1------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_27 (Conv1D)           (None, 33, 1)             4         \n",
            "_________________________________________________________________\n",
            "flatten_27 (Flatten)         (None, 33)                0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 300)               10200     \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 150)               45150     \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 55,505\n",
            "Trainable params: 55,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10380/10380 [==============================] - 2s 221us/step - loss: 61.9977 - mean_absolute_error: 4.5807\n",
            "Epoch 2/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 36.6983 - mean_absolute_error: 3.4215\n",
            "Epoch 3/50\n",
            "10380/10380 [==============================] - 1s 71us/step - loss: 26.0231 - mean_absolute_error: 2.8635\n",
            "Epoch 4/50\n",
            "10380/10380 [==============================] - 1s 72us/step - loss: 20.8808 - mean_absolute_error: 2.5661\n",
            "Epoch 5/50\n",
            "10380/10380 [==============================] - 1s 68us/step - loss: 17.7686 - mean_absolute_error: 2.3734\n",
            "Epoch 6/50\n",
            "10380/10380 [==============================] - 1s 65us/step - loss: 16.4507 - mean_absolute_error: 2.2619\n",
            "Epoch 7/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 14.6403 - mean_absolute_error: 2.1736\n",
            "Epoch 8/50\n",
            "10380/10380 [==============================] - 1s 62us/step - loss: 14.0431 - mean_absolute_error: 2.0832\n",
            "Epoch 9/50\n",
            "10380/10380 [==============================] - 1s 61us/step - loss: 13.7849 - mean_absolute_error: 2.0706\n",
            "Epoch 10/50\n",
            "10380/10380 [==============================] - 1s 71us/step - loss: 13.9195 - mean_absolute_error: 2.0781\n",
            "Epoch 11/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 12.8324 - mean_absolute_error: 1.9837\n",
            "Epoch 12/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 12.3887 - mean_absolute_error: 1.9355\n",
            "Epoch 13/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 11.9113 - mean_absolute_error: 1.9115\n",
            "Epoch 14/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 11.5892 - mean_absolute_error: 1.8778\n",
            "Epoch 15/50\n",
            "10380/10380 [==============================] - 1s 60us/step - loss: 11.0654 - mean_absolute_error: 1.8434\n",
            "Epoch 16/50\n",
            "10380/10380 [==============================] - 1s 67us/step - loss: 10.9585 - mean_absolute_error: 1.8351\n",
            "Epoch 17/50\n",
            "10380/10380 [==============================] - 1s 72us/step - loss: 11.1541 - mean_absolute_error: 1.8348\n",
            "Epoch 18/50\n",
            "10380/10380 [==============================] - 1s 60us/step - loss: 10.3874 - mean_absolute_error: 1.7954\n",
            "Epoch 19/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 10.3224 - mean_absolute_error: 1.7724\n",
            "Epoch 20/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 9.9417 - mean_absolute_error: 1.7562\n",
            "Epoch 21/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 10.2410 - mean_absolute_error: 1.7589\n",
            "Epoch 22/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 9.0739 - mean_absolute_error: 1.7031\n",
            "Epoch 23/50\n",
            "10380/10380 [==============================] - 1s 66us/step - loss: 9.8291 - mean_absolute_error: 1.7173\n",
            "Epoch 24/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 10.0261 - mean_absolute_error: 1.7320\n",
            "Epoch 25/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 9.4946 - mean_absolute_error: 1.6828\n",
            "Epoch 26/50\n",
            "10380/10380 [==============================] - 1s 75us/step - loss: 9.2357 - mean_absolute_error: 1.6830\n",
            "Epoch 27/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 9.0723 - mean_absolute_error: 1.6633\n",
            "Epoch 28/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 9.2078 - mean_absolute_error: 1.6598\n",
            "Epoch 29/50\n",
            "10380/10380 [==============================] - 1s 79us/step - loss: 9.0741 - mean_absolute_error: 1.6697\n",
            "Epoch 30/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 8.7318 - mean_absolute_error: 1.6316\n",
            "Epoch 31/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 9.0413 - mean_absolute_error: 1.6294\n",
            "Epoch 32/50\n",
            "10380/10380 [==============================] - 1s 69us/step - loss: 7.9506 - mean_absolute_error: 1.5892\n",
            "Epoch 33/50\n",
            "10380/10380 [==============================] - 1s 60us/step - loss: 8.6675 - mean_absolute_error: 1.6170\n",
            "Epoch 34/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 8.2998 - mean_absolute_error: 1.6085\n",
            "Epoch 35/50\n",
            "10380/10380 [==============================] - 1s 74us/step - loss: 8.8767 - mean_absolute_error: 1.6291\n",
            "Epoch 36/50\n",
            "10380/10380 [==============================] - 1s 67us/step - loss: 8.1163 - mean_absolute_error: 1.5810\n",
            "Epoch 37/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 7.9482 - mean_absolute_error: 1.5644\n",
            "Epoch 38/50\n",
            "10380/10380 [==============================] - 1s 67us/step - loss: 7.5181 - mean_absolute_error: 1.5332\n",
            "Epoch 39/50\n",
            "10380/10380 [==============================] - 1s 62us/step - loss: 8.0803 - mean_absolute_error: 1.5726\n",
            "Epoch 40/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 7.7764 - mean_absolute_error: 1.5481\n",
            "Epoch 41/50\n",
            "10380/10380 [==============================] - 1s 70us/step - loss: 7.5865 - mean_absolute_error: 1.5364\n",
            "Epoch 42/50\n",
            "10380/10380 [==============================] - 1s 65us/step - loss: 7.6840 - mean_absolute_error: 1.5300\n",
            "Epoch 43/50\n",
            "10380/10380 [==============================] - 1s 62us/step - loss: 7.4071 - mean_absolute_error: 1.5227\n",
            "Epoch 44/50\n",
            "10380/10380 [==============================] - 1s 67us/step - loss: 8.0301 - mean_absolute_error: 1.5480\n",
            "Epoch 45/50\n",
            "10380/10380 [==============================] - 1s 62us/step - loss: 7.6725 - mean_absolute_error: 1.5310\n",
            "Epoch 46/50\n",
            "10380/10380 [==============================] - 1s 83us/step - loss: 7.4546 - mean_absolute_error: 1.5146\n",
            "Epoch 47/50\n",
            "10380/10380 [==============================] - 1s 72us/step - loss: 7.2639 - mean_absolute_error: 1.4903\n",
            "Epoch 48/50\n",
            "10380/10380 [==============================] - 1s 66us/step - loss: 7.1060 - mean_absolute_error: 1.4893\n",
            "Epoch 49/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 7.2003 - mean_absolute_error: 1.4919\n",
            "Epoch 50/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 7.0274 - mean_absolute_error: 1.4781\n",
            "Kappa score: 0.9577925107716411\n",
            "------------------Fold 2------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_28 (Conv1D)           (None, 33, 1)             4         \n",
            "_________________________________________________________________\n",
            "flatten_28 (Flatten)         (None, 33)                0         \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 300)               10200     \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 150)               45150     \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 55,505\n",
            "Trainable params: 55,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 2s 230us/step - loss: 59.1303 - mean_absolute_error: 4.2958\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 27.2427 - mean_absolute_error: 2.9518\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 19.0097 - mean_absolute_error: 2.4567\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 16.2843 - mean_absolute_error: 2.2863\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 15.0190 - mean_absolute_error: 2.1635\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 13.6244 - mean_absolute_error: 2.0826\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 12.8716 - mean_absolute_error: 2.0104\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 11.9203 - mean_absolute_error: 1.9505\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 11.2443 - mean_absolute_error: 1.9209\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 10.8108 - mean_absolute_error: 1.8739\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 1s 86us/step - loss: 10.3969 - mean_absolute_error: 1.8276\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 9.8145 - mean_absolute_error: 1.7943\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 9.8212 - mean_absolute_error: 1.7882\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 10.0145 - mean_absolute_error: 1.7810\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 9.1565 - mean_absolute_error: 1.7117\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 1s 87us/step - loss: 9.8137 - mean_absolute_error: 1.7630\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 9.2063 - mean_absolute_error: 1.7052\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 8.7594 - mean_absolute_error: 1.6906\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 9.0193 - mean_absolute_error: 1.6837\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.5611 - mean_absolute_error: 1.6614\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 1s 86us/step - loss: 8.6171 - mean_absolute_error: 1.6701\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 9.0730 - mean_absolute_error: 1.6705\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 1s 60us/step - loss: 8.8021 - mean_absolute_error: 1.6557\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.0454 - mean_absolute_error: 1.6117\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.0795 - mean_absolute_error: 1.6188\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 8.2214 - mean_absolute_error: 1.6104\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.1007 - mean_absolute_error: 1.6057\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 7.8814 - mean_absolute_error: 1.5819\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 7.8137 - mean_absolute_error: 1.5704\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.6330 - mean_absolute_error: 1.5565\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 7.9259 - mean_absolute_error: 1.5776\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 7.4439 - mean_absolute_error: 1.5546\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 7.5649 - mean_absolute_error: 1.5305\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.4805 - mean_absolute_error: 1.5307\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 7.1055 - mean_absolute_error: 1.5123\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 7.5860 - mean_absolute_error: 1.5402\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 1s 74us/step - loss: 7.2001 - mean_absolute_error: 1.5039\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 7.3196 - mean_absolute_error: 1.5145\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 7.7114 - mean_absolute_error: 1.5348\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.3159 - mean_absolute_error: 1.5073\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 6.9053 - mean_absolute_error: 1.4741\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 1s 84us/step - loss: 7.0549 - mean_absolute_error: 1.4788\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.1296 - mean_absolute_error: 1.4811\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 7.1653 - mean_absolute_error: 1.4882\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 6.9088 - mean_absolute_error: 1.4707\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 6.3917 - mean_absolute_error: 1.4542\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 6.7724 - mean_absolute_error: 1.4585\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 6.6183 - mean_absolute_error: 1.4523\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 6.7404 - mean_absolute_error: 1.4669\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 6.2878 - mean_absolute_error: 1.4225\n",
            "Kappa score: 0.958560128918\n",
            "------------------Fold 3------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_29 (Conv1D)           (None, 33, 1)             4         \n",
            "_________________________________________________________________\n",
            "flatten_29 (Flatten)         (None, 33)                0         \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 300)               10200     \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 150)               45150     \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 55,505\n",
            "Trainable params: 55,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 2s 239us/step - loss: 54.4360 - mean_absolute_error: 4.2067\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 25.8886 - mean_absolute_error: 2.9904\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 19.3953 - mean_absolute_error: 2.5122\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 1s 60us/step - loss: 17.2499 - mean_absolute_error: 2.3385\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 15.0273 - mean_absolute_error: 2.1746\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 1s 74us/step - loss: 14.0050 - mean_absolute_error: 2.1053\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 1s 75us/step - loss: 13.7446 - mean_absolute_error: 2.0660\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 12.9632 - mean_absolute_error: 2.0009\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 11.6793 - mean_absolute_error: 1.9428\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 12.3340 - mean_absolute_error: 1.9207\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 11.0756 - mean_absolute_error: 1.8694\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 11.4118 - mean_absolute_error: 1.8679\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 1s 61us/step - loss: 11.1372 - mean_absolute_error: 1.8474\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 10.9876 - mean_absolute_error: 1.8198\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 10.5718 - mean_absolute_error: 1.7900\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 10.5160 - mean_absolute_error: 1.7822\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 10.0335 - mean_absolute_error: 1.7324\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 9.7673 - mean_absolute_error: 1.7167\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 9.2623 - mean_absolute_error: 1.6985\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 9.7960 - mean_absolute_error: 1.7228\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 9.6062 - mean_absolute_error: 1.7033\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 9.1215 - mean_absolute_error: 1.6759\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 9.3865 - mean_absolute_error: 1.6721\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 9.3324 - mean_absolute_error: 1.6808\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.7760 - mean_absolute_error: 1.6364\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.3255 - mean_absolute_error: 1.5984\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.8009 - mean_absolute_error: 1.6436\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 8.5514 - mean_absolute_error: 1.6124\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.4659 - mean_absolute_error: 1.6040\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 8.3279 - mean_absolute_error: 1.6021\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.4879 - mean_absolute_error: 1.6020\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.2246 - mean_absolute_error: 1.5890\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.0199 - mean_absolute_error: 1.5714\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 8.4735 - mean_absolute_error: 1.5835\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 8.3048 - mean_absolute_error: 1.5889\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 7.8435 - mean_absolute_error: 1.5619\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 7.7887 - mean_absolute_error: 1.5408\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 1s 61us/step - loss: 7.8808 - mean_absolute_error: 1.5469\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 1s 72us/step - loss: 7.7524 - mean_absolute_error: 1.5375\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 7.7648 - mean_absolute_error: 1.5369\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 7.6433 - mean_absolute_error: 1.5115\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 7.6803 - mean_absolute_error: 1.5283\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 7.1002 - mean_absolute_error: 1.4906\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 7.4306 - mean_absolute_error: 1.5143\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 1s 79us/step - loss: 7.2047 - mean_absolute_error: 1.4854\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 7.4013 - mean_absolute_error: 1.5035\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 7.1395 - mean_absolute_error: 1.4888\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 7.0379 - mean_absolute_error: 1.4814\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 7.0838 - mean_absolute_error: 1.4804\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.4143 - mean_absolute_error: 1.4887\n",
            "Kappa score: 0.9715029726509454\n",
            "------------------Fold 4------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_30 (Conv1D)           (None, 33, 1)             4         \n",
            "_________________________________________________________________\n",
            "flatten_30 (Flatten)         (None, 33)                0         \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 300)               10200     \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 150)               45150     \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 55,505\n",
            "Trainable params: 55,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 3s 243us/step - loss: 56.8449 - mean_absolute_error: 4.2935\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 26.9564 - mean_absolute_error: 3.1178\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 18.7091 - mean_absolute_error: 2.5123\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 15.9147 - mean_absolute_error: 2.2771\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 14.6097 - mean_absolute_error: 2.1562\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 14.0675 - mean_absolute_error: 2.1086\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 12.2215 - mean_absolute_error: 1.9809\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 12.6240 - mean_absolute_error: 2.0080\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 11.4830 - mean_absolute_error: 1.9366\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 11.5493 - mean_absolute_error: 1.9156\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 11.1544 - mean_absolute_error: 1.8669\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 10.8789 - mean_absolute_error: 1.8531\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 10.4996 - mean_absolute_error: 1.8216\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 10.5418 - mean_absolute_error: 1.8158\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 10.2531 - mean_absolute_error: 1.8072\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 10.3059 - mean_absolute_error: 1.7977\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 10.2239 - mean_absolute_error: 1.7841\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 9.7624 - mean_absolute_error: 1.7482\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 9.6580 - mean_absolute_error: 1.7434\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 9.9229 - mean_absolute_error: 1.7370\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 9.4425 - mean_absolute_error: 1.7109\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 9.1378 - mean_absolute_error: 1.6975\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 9.2159 - mean_absolute_error: 1.6892\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.7681 - mean_absolute_error: 1.6478\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.7335 - mean_absolute_error: 1.6595\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 9.0930 - mean_absolute_error: 1.6713\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 1s 87us/step - loss: 8.7097 - mean_absolute_error: 1.6593\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 8.8370 - mean_absolute_error: 1.6427\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.4343 - mean_absolute_error: 1.6197\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.0942 - mean_absolute_error: 1.5907\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 1s 74us/step - loss: 8.6873 - mean_absolute_error: 1.6309\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 8.3982 - mean_absolute_error: 1.6093\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.4247 - mean_absolute_error: 1.6083\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 8.1745 - mean_absolute_error: 1.5938\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 8.2913 - mean_absolute_error: 1.5895\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 1s 74us/step - loss: 7.9778 - mean_absolute_error: 1.5546\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 1s 73us/step - loss: 8.4155 - mean_absolute_error: 1.5823\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 7.8068 - mean_absolute_error: 1.5592\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 1s 61us/step - loss: 8.0827 - mean_absolute_error: 1.5601\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 1s 61us/step - loss: 7.7179 - mean_absolute_error: 1.5242\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 7.1918 - mean_absolute_error: 1.5042\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 7.4676 - mean_absolute_error: 1.5206\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 7.7105 - mean_absolute_error: 1.5257\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 7.6767 - mean_absolute_error: 1.5183\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 7.2856 - mean_absolute_error: 1.5147\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 6.8391 - mean_absolute_error: 1.4808\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 6.9678 - mean_absolute_error: 1.4873\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 7.1899 - mean_absolute_error: 1.4832\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.1961 - mean_absolute_error: 1.4915\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 7.3785 - mean_absolute_error: 1.5198\n",
            "Kappa score: 0.9626055325986949\n",
            "------------------Fold 5------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_31 (Conv1D)           (None, 33, 1)             4         \n",
            "_________________________________________________________________\n",
            "flatten_31 (Flatten)         (None, 33)                0         \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 300)               10200     \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 150)               45150     \n",
            "_________________________________________________________________\n",
            "dropout_62 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_93 (Dense)             (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 55,505\n",
            "Trainable params: 55,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 3s 244us/step - loss: 50.9838 - mean_absolute_error: 3.9252\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 23.6500 - mean_absolute_error: 2.7492\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 17.6237 - mean_absolute_error: 2.3305\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 14.9776 - mean_absolute_error: 2.1485\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 13.9990 - mean_absolute_error: 2.0829\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 13.1961 - mean_absolute_error: 2.0104\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 11.8723 - mean_absolute_error: 1.9343\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 11.4928 - mean_absolute_error: 1.8984\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 11.1930 - mean_absolute_error: 1.8782\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 10.7282 - mean_absolute_error: 1.8423\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 10.6912 - mean_absolute_error: 1.8122\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 10.7029 - mean_absolute_error: 1.8236\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 10.0577 - mean_absolute_error: 1.7738\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 9.5321 - mean_absolute_error: 1.7443\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 9.6269 - mean_absolute_error: 1.7288\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 9.4716 - mean_absolute_error: 1.7038\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.9795 - mean_absolute_error: 1.6666\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 1s 75us/step - loss: 8.8548 - mean_absolute_error: 1.6733\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.7142 - mean_absolute_error: 1.6441\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.6333 - mean_absolute_error: 1.6494\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 8.4221 - mean_absolute_error: 1.6259\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.7377 - mean_absolute_error: 1.6322\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 1s 86us/step - loss: 8.4518 - mean_absolute_error: 1.6221\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.2029 - mean_absolute_error: 1.5955\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.2154 - mean_absolute_error: 1.5875\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.1919 - mean_absolute_error: 1.5876\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.0440 - mean_absolute_error: 1.5718\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 7.4882 - mean_absolute_error: 1.5432\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.7439 - mean_absolute_error: 1.5381\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 7.5034 - mean_absolute_error: 1.5306\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 7.6056 - mean_absolute_error: 1.5201\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.7889 - mean_absolute_error: 1.5459\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 7.1462 - mean_absolute_error: 1.5056\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 7.3216 - mean_absolute_error: 1.5045\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.4678 - mean_absolute_error: 1.5181\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.3110 - mean_absolute_error: 1.4907\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 6.9744 - mean_absolute_error: 1.4691\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 6.8154 - mean_absolute_error: 1.4672\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 7.0870 - mean_absolute_error: 1.4769\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 6.8865 - mean_absolute_error: 1.4659\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 6.5836 - mean_absolute_error: 1.4415\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 6.6948 - mean_absolute_error: 1.4480\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 6.7855 - mean_absolute_error: 1.4462\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 6.7773 - mean_absolute_error: 1.4548\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 6.6152 - mean_absolute_error: 1.4300\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 6.4156 - mean_absolute_error: 1.4217\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 6.6976 - mean_absolute_error: 1.4349\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 6.5663 - mean_absolute_error: 1.4308\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 6.8701 - mean_absolute_error: 1.4346\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 6.5927 - mean_absolute_error: 1.4347\n",
            "Kappa score: 0.9674958146225644\n",
            "Best Score: 0.9715029726509454\n",
            "Average Kappa Score: 0.9635913919123691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndE_SitxyVfJ",
        "colab_type": "code",
        "outputId": "e71f5ec9-66f4-4eb2-cd97-b36334dcd33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model, history, score = train_model(X, Y, num_dims=50)\n",
        "save_model(model, history, \"50_64_50_trained\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------Fold 1------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_32 (Conv1D)           (None, 16, 1)             4         \n",
            "_________________________________________________________________\n",
            "flatten_32 (Flatten)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 300)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 150)               45150     \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 50,405\n",
            "Trainable params: 50,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10380/10380 [==============================] - 3s 258us/step - loss: 66.4224 - mean_absolute_error: 4.6297\n",
            "Epoch 2/50\n",
            "10380/10380 [==============================] - 1s 70us/step - loss: 34.4504 - mean_absolute_error: 3.5304\n",
            "Epoch 3/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 24.8504 - mean_absolute_error: 3.1213\n",
            "Epoch 4/50\n",
            "10380/10380 [==============================] - 1s 67us/step - loss: 20.9502 - mean_absolute_error: 2.8944\n",
            "Epoch 5/50\n",
            "10380/10380 [==============================] - 1s 66us/step - loss: 19.2006 - mean_absolute_error: 2.7730\n",
            "Epoch 6/50\n",
            "10380/10380 [==============================] - 1s 72us/step - loss: 17.6886 - mean_absolute_error: 2.6876\n",
            "Epoch 7/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 17.0227 - mean_absolute_error: 2.6326\n",
            "Epoch 8/50\n",
            "10380/10380 [==============================] - 1s 66us/step - loss: 16.2949 - mean_absolute_error: 2.5916\n",
            "Epoch 9/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 15.8813 - mean_absolute_error: 2.5493\n",
            "Epoch 10/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 16.0504 - mean_absolute_error: 2.5439\n",
            "Epoch 11/50\n",
            "10380/10380 [==============================] - 1s 67us/step - loss: 15.1533 - mean_absolute_error: 2.4934\n",
            "Epoch 12/50\n",
            "10380/10380 [==============================] - 1s 67us/step - loss: 14.8937 - mean_absolute_error: 2.4589\n",
            "Epoch 13/50\n",
            "10380/10380 [==============================] - 1s 66us/step - loss: 14.0799 - mean_absolute_error: 2.4003\n",
            "Epoch 14/50\n",
            "10380/10380 [==============================] - 1s 65us/step - loss: 14.0784 - mean_absolute_error: 2.4254\n",
            "Epoch 15/50\n",
            "10380/10380 [==============================] - 1s 64us/step - loss: 13.2746 - mean_absolute_error: 2.3781\n",
            "Epoch 16/50\n",
            "10380/10380 [==============================] - 1s 70us/step - loss: 13.4263 - mean_absolute_error: 2.3639\n",
            "Epoch 17/50\n",
            "10380/10380 [==============================] - 1s 69us/step - loss: 12.9128 - mean_absolute_error: 2.3394\n",
            "Epoch 18/50\n",
            "10380/10380 [==============================] - 1s 68us/step - loss: 12.8087 - mean_absolute_error: 2.3245\n",
            "Epoch 19/50\n",
            "10380/10380 [==============================] - 1s 65us/step - loss: 12.1786 - mean_absolute_error: 2.2947\n",
            "Epoch 20/50\n",
            "10380/10380 [==============================] - 1s 82us/step - loss: 12.3791 - mean_absolute_error: 2.2935\n",
            "Epoch 21/50\n",
            "10380/10380 [==============================] - 1s 73us/step - loss: 12.4181 - mean_absolute_error: 2.2870\n",
            "Epoch 22/50\n",
            "10380/10380 [==============================] - 1s 71us/step - loss: 12.3823 - mean_absolute_error: 2.2769\n",
            "Epoch 23/50\n",
            "10380/10380 [==============================] - 1s 78us/step - loss: 12.0501 - mean_absolute_error: 2.2527\n",
            "Epoch 24/50\n",
            "10380/10380 [==============================] - 1s 69us/step - loss: 11.8048 - mean_absolute_error: 2.2460\n",
            "Epoch 25/50\n",
            "10380/10380 [==============================] - 1s 67us/step - loss: 11.8165 - mean_absolute_error: 2.2468\n",
            "Epoch 26/50\n",
            "10380/10380 [==============================] - 1s 65us/step - loss: 11.5605 - mean_absolute_error: 2.2199\n",
            "Epoch 27/50\n",
            "10380/10380 [==============================] - 1s 65us/step - loss: 11.1518 - mean_absolute_error: 2.2054\n",
            "Epoch 28/50\n",
            "10380/10380 [==============================] - 1s 66us/step - loss: 11.4707 - mean_absolute_error: 2.2011\n",
            "Epoch 29/50\n",
            "10380/10380 [==============================] - 1s 68us/step - loss: 11.0124 - mean_absolute_error: 2.1873\n",
            "Epoch 30/50\n",
            "10380/10380 [==============================] - 1s 67us/step - loss: 10.7495 - mean_absolute_error: 2.1523\n",
            "Epoch 31/50\n",
            "10380/10380 [==============================] - 1s 65us/step - loss: 11.0360 - mean_absolute_error: 2.1742\n",
            "Epoch 32/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 11.0780 - mean_absolute_error: 2.1764\n",
            "Epoch 33/50\n",
            "10380/10380 [==============================] - 1s 62us/step - loss: 11.0599 - mean_absolute_error: 2.1517\n",
            "Epoch 34/50\n",
            "10380/10380 [==============================] - 1s 62us/step - loss: 11.1486 - mean_absolute_error: 2.1669\n",
            "Epoch 35/50\n",
            "10380/10380 [==============================] - 1s 68us/step - loss: 10.8083 - mean_absolute_error: 2.1417\n",
            "Epoch 36/50\n",
            "10380/10380 [==============================] - 1s 62us/step - loss: 10.4278 - mean_absolute_error: 2.1362\n",
            "Epoch 37/50\n",
            "10380/10380 [==============================] - 1s 75us/step - loss: 10.2682 - mean_absolute_error: 2.1045\n",
            "Epoch 38/50\n",
            "10380/10380 [==============================] - 1s 76us/step - loss: 10.1345 - mean_absolute_error: 2.0953\n",
            "Epoch 39/50\n",
            "10380/10380 [==============================] - 1s 69us/step - loss: 10.1146 - mean_absolute_error: 2.0912\n",
            "Epoch 40/50\n",
            "10380/10380 [==============================] - 1s 65us/step - loss: 10.4696 - mean_absolute_error: 2.1175\n",
            "Epoch 41/50\n",
            "10380/10380 [==============================] - 1s 66us/step - loss: 9.9155 - mean_absolute_error: 2.0661\n",
            "Epoch 42/50\n",
            "10380/10380 [==============================] - 1s 85us/step - loss: 10.1033 - mean_absolute_error: 2.0847\n",
            "Epoch 43/50\n",
            "10380/10380 [==============================] - 1s 61us/step - loss: 10.0240 - mean_absolute_error: 2.0747\n",
            "Epoch 44/50\n",
            "10380/10380 [==============================] - 1s 68us/step - loss: 9.8390 - mean_absolute_error: 2.0553\n",
            "Epoch 45/50\n",
            "10380/10380 [==============================] - 1s 65us/step - loss: 9.8045 - mean_absolute_error: 2.0527\n",
            "Epoch 46/50\n",
            "10380/10380 [==============================] - 1s 62us/step - loss: 9.6687 - mean_absolute_error: 2.0432\n",
            "Epoch 47/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 9.5304 - mean_absolute_error: 2.0497\n",
            "Epoch 48/50\n",
            "10380/10380 [==============================] - 1s 63us/step - loss: 9.4209 - mean_absolute_error: 2.0229\n",
            "Epoch 49/50\n",
            "10380/10380 [==============================] - 1s 67us/step - loss: 9.4215 - mean_absolute_error: 2.0349\n",
            "Epoch 50/50\n",
            "10380/10380 [==============================] - 1s 67us/step - loss: 9.4659 - mean_absolute_error: 2.0330\n",
            "Kappa score: 0.9580089308099391\n",
            "------------------Fold 2------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_33 (Conv1D)           (None, 16, 1)             4         \n",
            "_________________________________________________________________\n",
            "flatten_33 (Flatten)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 300)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_65 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 150)               45150     \n",
            "_________________________________________________________________\n",
            "dropout_66 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 50,405\n",
            "Trainable params: 50,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 3s 304us/step - loss: 57.6878 - mean_absolute_error: 4.2417\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 26.5251 - mean_absolute_error: 3.0422\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 20.7831 - mean_absolute_error: 2.5896\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 17.8087 - mean_absolute_error: 2.4187\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 1s 99us/step - loss: 16.5186 - mean_absolute_error: 2.3147\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 15.4237 - mean_absolute_error: 2.2182\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 14.0788 - mean_absolute_error: 2.1168\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 13.3082 - mean_absolute_error: 2.0525\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 12.5558 - mean_absolute_error: 2.0227\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 12.6956 - mean_absolute_error: 2.0013\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 11.7288 - mean_absolute_error: 1.9490\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 11.6454 - mean_absolute_error: 1.9191\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 11.0259 - mean_absolute_error: 1.8678\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 11.3533 - mean_absolute_error: 1.8722\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 1s 61us/step - loss: 11.1262 - mean_absolute_error: 1.8759\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 10.6091 - mean_absolute_error: 1.8231\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 10.3071 - mean_absolute_error: 1.8059\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 1s 61us/step - loss: 10.1089 - mean_absolute_error: 1.7780\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 10.0011 - mean_absolute_error: 1.7685\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 10.0567 - mean_absolute_error: 1.7752\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 9.5162 - mean_absolute_error: 1.7280\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 9.4893 - mean_absolute_error: 1.7223\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 9.2755 - mean_absolute_error: 1.7170\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.9673 - mean_absolute_error: 1.6935\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 9.3302 - mean_absolute_error: 1.7088\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 1s 78us/step - loss: 8.8324 - mean_absolute_error: 1.6739\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 8.8179 - mean_absolute_error: 1.6768\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 9.4078 - mean_absolute_error: 1.6872\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 8.8775 - mean_absolute_error: 1.6565\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 1s 75us/step - loss: 9.0076 - mean_absolute_error: 1.6731\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 1s 75us/step - loss: 8.7700 - mean_absolute_error: 1.6605\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 8.6779 - mean_absolute_error: 1.6561\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 8.9456 - mean_absolute_error: 1.6495\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.3460 - mean_absolute_error: 1.6102\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.1869 - mean_absolute_error: 1.5976\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 8.3470 - mean_absolute_error: 1.6050\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.2091 - mean_absolute_error: 1.5904\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 8.4108 - mean_absolute_error: 1.6017\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 8.0428 - mean_absolute_error: 1.5800\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.8535 - mean_absolute_error: 1.5671\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.0623 - mean_absolute_error: 1.5863\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 7.7863 - mean_absolute_error: 1.5639\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 7.5634 - mean_absolute_error: 1.5452\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.1977 - mean_absolute_error: 1.5911\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 7.7479 - mean_absolute_error: 1.5485\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 7.4455 - mean_absolute_error: 1.5435\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 7.7491 - mean_absolute_error: 1.5523\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 7.6008 - mean_absolute_error: 1.5416\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.7193 - mean_absolute_error: 1.5525\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 7.3718 - mean_absolute_error: 1.5195\n",
            "Kappa score: 0.9530311956705108\n",
            "------------------Fold 3------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_34 (Conv1D)           (None, 16, 1)             4         \n",
            "_________________________________________________________________\n",
            "flatten_34 (Flatten)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 300)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_67 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_101 (Dense)            (None, 150)               45150     \n",
            "_________________________________________________________________\n",
            "dropout_68 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 50,405\n",
            "Trainable params: 50,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 3s 271us/step - loss: 57.8301 - mean_absolute_error: 4.3461\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 33.2064 - mean_absolute_error: 3.3824\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 25.4823 - mean_absolute_error: 3.0805\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 21.4698 - mean_absolute_error: 2.8633\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 19.4933 - mean_absolute_error: 2.6998\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 17.6980 - mean_absolute_error: 2.5771\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 15.8684 - mean_absolute_error: 2.4519\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 15.0526 - mean_absolute_error: 2.4170\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 15.5097 - mean_absolute_error: 2.3803\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 13.9884 - mean_absolute_error: 2.2102\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 12.6347 - mean_absolute_error: 2.0292\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 12.7464 - mean_absolute_error: 2.0128\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 1s 72us/step - loss: 12.8337 - mean_absolute_error: 1.9983\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 12.4487 - mean_absolute_error: 1.9576\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 11.9872 - mean_absolute_error: 1.9296\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 11.3525 - mean_absolute_error: 1.8727\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 11.0465 - mean_absolute_error: 1.8457\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 10.8862 - mean_absolute_error: 1.8369\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 10.5818 - mean_absolute_error: 1.8071\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 10.8306 - mean_absolute_error: 1.7986\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 11.0105 - mean_absolute_error: 1.7882\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 10.6538 - mean_absolute_error: 1.7822\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 10.7194 - mean_absolute_error: 1.7841\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 10.3304 - mean_absolute_error: 1.7488\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 9.9450 - mean_absolute_error: 1.7288\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 10.1196 - mean_absolute_error: 1.7430\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 9.6601 - mean_absolute_error: 1.7083\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 9.5788 - mean_absolute_error: 1.7168\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 9.3967 - mean_absolute_error: 1.6865\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 9.2619 - mean_absolute_error: 1.6788\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 9.2055 - mean_absolute_error: 1.6810\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 1s 74us/step - loss: 9.4845 - mean_absolute_error: 1.6806\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 9.1286 - mean_absolute_error: 1.6685\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 9.4499 - mean_absolute_error: 1.6771\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 1s 82us/step - loss: 9.7549 - mean_absolute_error: 1.6747\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.9433 - mean_absolute_error: 1.6340\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 9.0598 - mean_absolute_error: 1.6410\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 9.1453 - mean_absolute_error: 1.6281\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 9.0808 - mean_absolute_error: 1.6423\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.4306 - mean_absolute_error: 1.5970\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 9.0153 - mean_absolute_error: 1.6349\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 1s 61us/step - loss: 8.6410 - mean_absolute_error: 1.6080\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 8.5859 - mean_absolute_error: 1.6104\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.1159 - mean_absolute_error: 1.5852\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.9357 - mean_absolute_error: 1.6244\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 8.3662 - mean_absolute_error: 1.5871\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.6150 - mean_absolute_error: 1.5949\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.1994 - mean_absolute_error: 1.5710\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 1s 87us/step - loss: 8.6715 - mean_absolute_error: 1.5892\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.2507 - mean_absolute_error: 1.5664\n",
            "Kappa score: 0.9523548608389932\n",
            "------------------Fold 4------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_35 (Conv1D)           (None, 16, 1)             4         \n",
            "_________________________________________________________________\n",
            "flatten_35 (Flatten)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 300)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_69 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 150)               45150     \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 50,405\n",
            "Trainable params: 50,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 3s 298us/step - loss: 57.4865 - mean_absolute_error: 4.3472\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 33.2965 - mean_absolute_error: 3.4908\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 25.0574 - mean_absolute_error: 3.0828\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 21.7025 - mean_absolute_error: 2.9020\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 18.8835 - mean_absolute_error: 2.7552\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 16.9304 - mean_absolute_error: 2.6285\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 16.1055 - mean_absolute_error: 2.5391\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 15.1804 - mean_absolute_error: 2.3733\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 14.7674 - mean_absolute_error: 2.1986\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 13.7950 - mean_absolute_error: 2.1218\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 1s 80us/step - loss: 13.0318 - mean_absolute_error: 2.0477\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 12.4617 - mean_absolute_error: 2.0199\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 12.3517 - mean_absolute_error: 1.9711\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 1s 61us/step - loss: 11.6298 - mean_absolute_error: 1.9262\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 12.0833 - mean_absolute_error: 1.9493\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 1s 85us/step - loss: 11.6926 - mean_absolute_error: 1.9156\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 11.5802 - mean_absolute_error: 1.8978\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 11.2153 - mean_absolute_error: 1.8760\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 11.1891 - mean_absolute_error: 1.8593\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 1s 60us/step - loss: 10.7793 - mean_absolute_error: 1.8254\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 11.0098 - mean_absolute_error: 1.8366\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 10.1820 - mean_absolute_error: 1.7849\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 10.2407 - mean_absolute_error: 1.7651\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 9.9854 - mean_absolute_error: 1.7480\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 9.6732 - mean_absolute_error: 1.7308\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 9.9759 - mean_absolute_error: 1.7508\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 9.9187 - mean_absolute_error: 1.7300\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 10.1006 - mean_absolute_error: 1.7496\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 9.4489 - mean_absolute_error: 1.7027\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 9.3087 - mean_absolute_error: 1.6906\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 9.4124 - mean_absolute_error: 1.6895\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 9.3200 - mean_absolute_error: 1.6869\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 9.3568 - mean_absolute_error: 1.6860\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 1s 70us/step - loss: 9.4740 - mean_absolute_error: 1.6750\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.8335 - mean_absolute_error: 1.6462\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 9.3122 - mean_absolute_error: 1.6727\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 1s 77us/step - loss: 8.6296 - mean_absolute_error: 1.6322\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.7309 - mean_absolute_error: 1.6361\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 8.3837 - mean_absolute_error: 1.5947\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 8.5018 - mean_absolute_error: 1.6139\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.3512 - mean_absolute_error: 1.5959\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 1s 83us/step - loss: 8.4299 - mean_absolute_error: 1.6145\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 8.2003 - mean_absolute_error: 1.5793\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.4534 - mean_absolute_error: 1.5952\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.5091 - mean_absolute_error: 1.5986\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 1s 71us/step - loss: 8.5982 - mean_absolute_error: 1.6233\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 7.9871 - mean_absolute_error: 1.5693\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.1304 - mean_absolute_error: 1.5935\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.3082 - mean_absolute_error: 1.5846\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.3634 - mean_absolute_error: 1.5828\n",
            "Kappa score: 0.9509559926171701\n",
            "------------------Fold 5------------------\n",
            "Word2Vec model trained\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_36 (Conv1D)           (None, 16, 1)             4         \n",
            "_________________________________________________________________\n",
            "flatten_36 (Flatten)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 300)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_71 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 150)               45150     \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 50,405\n",
            "Trainable params: 50,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 3s 289us/step - loss: 74.7000 - mean_absolute_error: 5.1267\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 40.1535 - mean_absolute_error: 3.7861\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 29.8919 - mean_absolute_error: 3.3836\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 1s 86us/step - loss: 23.2437 - mean_absolute_error: 2.9582\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 19.2923 - mean_absolute_error: 2.5568\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 17.5021 - mean_absolute_error: 2.4038\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 15.9081 - mean_absolute_error: 2.2703\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 15.6974 - mean_absolute_error: 2.2403\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 14.9144 - mean_absolute_error: 2.1919\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 13.8509 - mean_absolute_error: 2.1005\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 13.1037 - mean_absolute_error: 2.0489\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 13.7719 - mean_absolute_error: 2.0609\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 12.6369 - mean_absolute_error: 1.9943\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 12.9345 - mean_absolute_error: 1.9772\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 11.6775 - mean_absolute_error: 1.9126\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 11.6260 - mean_absolute_error: 1.8936\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 11.1304 - mean_absolute_error: 1.8713\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 10.8305 - mean_absolute_error: 1.8478\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 10.7214 - mean_absolute_error: 1.8296\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 10.5345 - mean_absolute_error: 1.8066\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 10.2497 - mean_absolute_error: 1.7900\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 10.0001 - mean_absolute_error: 1.7634\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 9.9095 - mean_absolute_error: 1.7603\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 9.8049 - mean_absolute_error: 1.7443\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 9.8311 - mean_absolute_error: 1.7381\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 9.3054 - mean_absolute_error: 1.6954\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 9.6703 - mean_absolute_error: 1.7250\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 1s 69us/step - loss: 9.4505 - mean_absolute_error: 1.6954\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 9.4974 - mean_absolute_error: 1.6859\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 9.4292 - mean_absolute_error: 1.6954\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 9.0246 - mean_absolute_error: 1.6614\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 8.8483 - mean_absolute_error: 1.6471\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 9.0566 - mean_absolute_error: 1.6523\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 8.7945 - mean_absolute_error: 1.6476\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 1s 65us/step - loss: 8.4882 - mean_absolute_error: 1.6170\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 1s 64us/step - loss: 8.5278 - mean_absolute_error: 1.6149\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 1s 63us/step - loss: 8.7948 - mean_absolute_error: 1.6240\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.2889 - mean_absolute_error: 1.5861\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.4724 - mean_absolute_error: 1.6045\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 1s 72us/step - loss: 8.3585 - mean_absolute_error: 1.5964\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 8.4193 - mean_absolute_error: 1.5893\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.4405 - mean_absolute_error: 1.5744\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 1s 73us/step - loss: 7.6701 - mean_absolute_error: 1.5428\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 1s 68us/step - loss: 8.0501 - mean_absolute_error: 1.5618\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 1s 67us/step - loss: 8.2131 - mean_absolute_error: 1.5630\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 1s 86us/step - loss: 7.8173 - mean_absolute_error: 1.5309\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 8.1872 - mean_absolute_error: 1.5648\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 1s 66us/step - loss: 7.9274 - mean_absolute_error: 1.5412\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 1s 75us/step - loss: 8.0594 - mean_absolute_error: 1.5466\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 1s 62us/step - loss: 7.7305 - mean_absolute_error: 1.5259\n",
            "Kappa score: 0.9502917671511876\n",
            "Best Score: 0.9580089308099391\n",
            "Average Kappa Score: 0.9529285494175601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbMbO75BF0qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}